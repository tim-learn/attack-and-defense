# [Oakland S&P](https://sp2023.ieee-security.org/program-papers.html)

## Adversarial Attack

### Attack

1. "StyleFool: Fooling Video Classification Systems via Style Transfer" [[Paper]](https://ieeexplore.ieee.org/document/10179383)
   - Yuxin Cao; Xi Xiao; Ruoxi Sun; Derui Wang; Minhui Xue; Sheng Wen

2. "ADI: Adversarial Dominating Inputs in Vertical Federated Learning Systems" [[Paper]](https://arxiv.org/abs/2201.02775)
   - Qi Pang; Yuanyuan Yuan; Shuai Wang; Wenting Zheng

### Defense

1. "AI-Guardian: Defeating Adversarial Attacks using Backdoors" [[Paper]](https://ieeexplore.ieee.org/document/10179473)
   - Hong Zhu; Shengzhi Zhang; Kai Chen

2. "SoK: Certified Robustness for Deep Neural Networks" [[Paper]](https://ieeexplore.ieee.org/document/10179303)
   - Linyi Li; Tao Xie; Bo Li

3. "On The Empirical Effectiveness of Unrealistic Adversarial Hardening Against Realistic Adversarial Attacks" [[Paper]](https://ieeexplore.ieee.org/document/10179316) [[Code]](https://github.com/serval-uni-lu/realistic_adversarial_hardening)
   - Salijona Dyrmishi; Salah Ghamizi; Thibault Simonetto; Yves Le Traon; Maxime Cordy

## Backdoor Attack

### Attack

1. "Disguising Attacks with Explanation-Aware Backdoors" [[Paper]](https://ieeexplore.ieee.org/document/10179308)
   - Maximilian Noppel; Lukas Peter; Christian Wressnegger

2. "3DFed: Adaptive and Extensible Framework for Covert Backdoor Attack in Federated Learning" [[Paper]](https://ieeexplore.ieee.org/abstract/document/10179401)
   - Haoyang Li; Qingqing Ye; Haibo Hu; Jin Li; Leixia Wang; Chengfang Fang; Jie Shi

3. "Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers" [[Paper]](https://ieeexplore.ieee.org/document/10179347)
   - Limin Yang; Zhi Chen; Jacopo Cortellazzi; Feargus Pendlebury; Kevin Tu; Fabio Pierazzi; Lorenzo Cavallaro; Gang Wang

4. "TrojanModel: A Practical Trojan Attack against Automatic Speech Recognition Systems" [[Paper]](https://ieeexplore.ieee.org/document/10179331)
   - Wei Zong; Yang-Wai Chow; Willy Susilo; Kien Do; Svetha Venkatesh

### Defense

1. "Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models" [[Paper]](https://arxiv.org/abs/2212.04687)
   - Rui Zhu; Di Tang; Siyuan Tang; XiaoFeng Wang; Haixu Tang

2. "BayBFed: Bayesian Backdoor Defense for Federated Learning" [[Paper]](https://ieeexplore.ieee.org/document/10179362)
   - Kavita Kumari; Phillip Rieger; Hossein Fereidooni; Murtuza Jadliwala; Ahmad-Reza Sadeghi

3. "FedRecover: Recovering from Poisoning Attacks in Federated Learning using Historical Information" [[Paper]](https://ieeexplore.ieee.org/document/10179336)
   - Xiaoyu Cao; Jinyuan Jia; Zaixi Zhang; Neil Zhenqiang Gong

4. "Redeem Myself: Purifying Backdoors in Deep Learning Models using Self Attention Distillation" [[Paper]](https://ieeexplore.ieee.org/document/10179375)
   - Xueluan Gong; Yanjiao Chen; Wang Yang; Qian Wang; Yuzhe Gu; Huayang Huang; Chao Shenz

5. "RAB: Provable Robustness Against Backdoor Attacks" [[Paper]](https://ieeexplore.ieee.org/document/10179451)
   - Maurice Weber; Xiaojun Xu; Bojan Karlaš; Ce Zhang; Bo Li

## Federated Learning

1. "Flamingo: Multi-Round Single-Server Secure Aggregation with Applications to Private Federated Learning" [[Paper]](https://ieeexplore.ieee.org/document/10179434)
   - Yiping Ma; Jess Woods; Sebastian Angel; Antigoni Polychroniadou; Tal Rabin

2. "ELSA: Secure Aggregation for Federated Learning with Malicious Actors" [[Paper]](https://ieeexplore.ieee.org/document/10179468)
   - Mayank Rathee; Conghao Shen; Sameer Wagh; Raluca Ada Popa

3. "Private, Efficient, and Accurate: Protecting Models Trained by Multi-party Learning with Differential Privacy" [[Paper]](https://ieeexplore.ieee.org/document/10179422)
   - Wenqiang Ruan; Mingxin Xu; Wenjing Fang; Li Wang; Lei Wang; Weili Han

4. "Spectral-DP: Differentially Private Deep Learning through Spectral Perturbation and Filtering" [[Paper]](https://ieeexplore.ieee.org/document/10179457)
   - Ce Feng; Nuo Xu; Wujie Wen; Parv Venkitasubramaniam; Caiwen Ding

5. "RoFL: Robustness of Secure Federated Learning" [[Paper]](https://ieeexplore.ieee.org/document/10179400)
   - Hidde Lycklama; Lukas Burkhalter; Alexander Viand; Nicolas Küchler; Anwar Hithnawi

## Decentralized Learning

1. "On the (In)security of Peer-to-Peer Decentralized Machine Learning" [[Paper]](https://www.computer.org/csdl/proceedings-article/sp/2023/933600a418/1NrbXMPH8QM)
   - Dario Pasquini; Mathilde Raynal; Carmela Troncoso

## Inference Privacy

1. "SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning" [[Paper]](https://ieeexplore.ieee.org/abstract/document/10179281)
   - Ahmed Salem; Giovanni Cherubin; David Evans; Boris Köpf; Andrew Paverd; Anshuman Suri; Shruti Tople; Santiago Zanella-Béguelin

2. "Analyzing Leakage of Personally Identifiable Information in Language Models" [[Paper]](https://ieeexplore.ieee.org/document/10179300) [[Code]](https://github.com/microsoft/analysing_pii_leakage)
   - Nils Lukas; Ahmed Salem; Robert Sim; Shruti Tople; Lukas Wutschitz; Santiago Zanella-Béguelin

### Membership Inference Attack

1. "Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference Perspective" [[Paper]](https://ieeexplore.ieee.org/document/10179463)
   - Shahbaz Rezaei; Zubair Shafiq; Xin Liu

### Property Inference Attack

1. "SNAP: Efficient Extraction of Private Properties with Poisoning" [[Paper]](https://ieeexplore.ieee.org/document/10179334)
   - Harsh Chaudhari; John Abascal; Alina Oprea; Matthew Jagielski; Florian Tramèr; Jonathan Ullman

## Intellectual Property

### Fingerprint

1. "PublicCheck: Public Integrity Verification for Services of Run-time Deep Models" [[Paper]](https://ieeexplore.ieee.org/abstract/document/10179380)
   - Shuo Wang; Sharif Abuadbba; Sidharth Agarwal; Kristen Moore; Ruoxi Sun; Minhui Xue; Surya Nepal; Seyit Camtepe; Salil Kanhere

### Model Extraction Attack

1. "D-DAE: Defense-Penetrating Model Extraction Attacks" [[Paper]](https://ieeexplore.ieee.org/document/10179406)
   - Yanjiao Chen; Rui Guan; Xueluan Gong; Jianshuo Dong; Meng Xue

## Others

1. "On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive Learning" [[Paper]](https://ieeexplore.ieee.org/document/10179315) [[Code]](https://github.com/YitingQu/meme-evolution)
   - Yiting Qu; Xinlei He; Shannon Pierson; Michael Backes; Yang Zhang; Savvas Zannettou

2. "Deepfake Text Detection: Limitations and Opportunities" [[Paper]](https://ieeexplore.ieee.org/document/10179387)
   - Jiameng Pu; Zain Sarwar; Sifat Muhammad Abdullah; Abdullah Rehman; Yoonjin Kim; Parantapa Bhattacharya; Mobin Javed; Bimal Viswanath

3. "GeeSolver: A Generic, Efficient, and Effortless Solver with Self-Supervised Learning for Breaking Text Captchas" [[Paper]](https://ieeexplore.ieee.org/document/10179379)
   - Ruijie Zhao; Xianwen Deng; Yanhao Wang; Zhicong Yan; Zhengguang Han; Libo Chen; Zhi Xue; Yijun Wang

4. "Examining Zero-Shot Vulnerability Repair with Large Language Models" [[Paper]](https://ieeexplore.ieee.org/document/10179324)
   - Hammond Pearce; Benjamin Tan; Baleegh Ahmad; Ramesh Karri; Brendan Dolan-Gavitt
5. "Callee: Recovering Call Graphs for Binaries with Transfer and Contrastive Learning" [[Paper]](https://ieeexplore.ieee.org/document/10179482)
   - Wenyu Zhu; Zhiyao Feng; Zihan Zhang; Jianjun Chen; Zhijian Ou; Min Yang; Chao Zhang


# ACM CCS

# [USENIX Security](https://www.usenix.org/conference/usenixsecurity23/summer-accepted-papers)

# [NDSS](https://www.ndss-symposium.org/ndss2023/accepted-papers/)

## Adversarial Attack

### Attack

1. "Adversarial Robustness for Tabular Data through Cost and Utility Awareness" [[Paper]](https://www.ndss-symposium.org/ndss-paper/adversarial-robustness-for-tabular-data-through-cost-and-utility-awareness/)
   - Klim Kireev; Bogdan Kulynych; Carmela Troncoso

### Defense

1. "REaaS: Enabling Adversarially Robust Downstream Classifiers via Robust Encoder as a Service" [[Paper]](https://www.ndss-symposium.org/ndss-paper/reaas-enabling-adversarially-robust-downstream-classifiers-via-robust-encoder-as-a-service/)
   - Wenjie Qu; Jinyuan Jia; Neil Zhenqiang Gong

## Backdoor Attack

### Attack

1. "Backdoor Attacks Against Dataset Distillation" [[Paper]](https://www.ndss-symposium.org/ndss-paper/backdoor-attacks-against-dataset-distillation/) [[Code]](https://github.com/liuyugeng/baadd)
   - Yugeng Liu; Zheng Li; Michael Backes; Yun Shen; Yang Zhang

### Defense

1. "BEAGLE: Forensics of Deep Learning Backdoor Attack for Better Defense" [[Paper]](https://www.ndss-symposium.org/ndss-paper/beagle-forensics-of-deep-learning-backdoor-attack-for-better-defense/)
   - Siyuan Cheng; Guanhong Tao; Yingqi Liu; Shengwei An; Xiangzhe Xu; Shiwei Feng; Guangyu Shen; Kaiyuan Zhang; Qiuling Xu; Shiqing Ma; Xiangyu Zhang

## Intellectual Property

1. "RAI2: Responsible Identity Audit Governing the Artificial Intelligence" [[Paper]](https://www.ndss-symposium.org/ndss-paper/rai2-responsible-identity-audit-governing-the-artificial-intelligence/)
   - Tian Dong; Shaofeng Li; Guoxing Chen; Minhui Xue; Haojin Zhu; Zhen Liu

## Others

1. "Anomaly Detection in the Open World: Normality Shift Detection, Explanation, and Adaptation"[[Paper]](https://www.ndss-symposium.org/ndss-paper/anomaly-detection-in-the-open-world-normality-shift-detection-explanation-and-adaptation/) [[Code]](https://github.com/dongtsi/OWAD)
   - Dongqi Han; Zhiliang Wang; Wenqi Chen; Kai Wang; Rui Yu; Su Wang; Han Zhang; Zhihua Wang; Minghui Jin; Jiahai Yang; Xingang Shi; Xia Yin

2. "BARS: Local Robustness Certification for Deep Learning based Traffic Analysis Systems" [[Paper]](https://www.ndss-symposium.org/ndss-paper/bars-local-robustness-certification-for-deep-learning-based-traffic-analysis-systems/) [[Code]](https://github.com/KaiWangGitHub/BARS)
   - Kai Wang; Zhiliang Wang; Dongqi Han; Wenqi Chen; Jiahai Yang; Xingang Shi; Xia Yin
