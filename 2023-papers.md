# [Oakland S&P](https://sp2023.ieee-security.org/program-papers.html)

## Adversarial Attack
1. "AI-Guardian: Defeating Adversarial Attacks using Backdoors" [[Paper]](https://ieeexplore.ieee.org/document/10179473)
   - Hong Zhu; Shengzhi Zhang; Kai Chen

2. "SoK: Certified Robustness for Deep Neural Networks" [[Paper]](https://ieeexplore.ieee.org/document/10179303)
   - Linyi Li; Tao Xie; Bo Li


## Backdoor Attack

### Attack

1. "Disguising Attacks with Explanation-Aware Backdoors" [[Paper]](https://ieeexplore.ieee.org/document/10179308)
   - Maximilian Noppel; Lukas Peter; Christian Wressnegger
2. "Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers" [[Paper]](https://ieeexplore.ieee.org/document/10179347)
   - Limin Yang; Zhi Chen; Jacopo Cortellazzi; Feargus Pendlebury; Kevin Tu; Fabio Pierazzi; Lorenzo Cavallaro; Gang Wang

### Defense

1. "Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models" [[Paper]](https://arxiv.org/abs/2212.04687)
   - Rui Zhu; Di Tang; Siyuan Tang; XiaoFeng Wang; Haixu Tang
2. "BayBFed: Bayesian Backdoor Defense for Federated Learning" [[Paper]](https://ieeexplore.ieee.org/document/10179362)
   - Kavita Kumari; Phillip Rieger; Hossein Fereidooni; Murtuza Jadliwala; Ahmad-Reza Sadeghi

3. "Redeem Myself: Purifying Backdoors in Deep Learning Models using Self Attention Distillation" [[Paper]](https://ieeexplore.ieee.org/document/10179375)
   - Xueluan Gong; Yanjiao Chen; Wang Yang; Qian Wang; Yuzhe Gu; Huayang Huang; Chao Shenz

4. "RAB: Provable Robustness Against Backdoor Attacks" [[Paper]](https://ieeexplore.ieee.org/document/10179451)
   - Maurice Weber; Xiaojun Xu; Bojan Karlaš; Ce Zhang; Bo Li

## Federated Learning
1. "ELSA: Secure Aggregation for Federated Learning with Malicious Actors" [[Paper]](https://eprint.iacr.org/2022/1695)
   - Mayank Rathee; Conghao Shen; Sameer Wagh; Raluca Ada Popa

2. "RoFL: Robustness of Secure Federated Learning" [[Paper]](https://ieeexplore.ieee.org/document/10179400)
   - Hidde Lycklama; Lukas Burkhalter; Alexander Viand; Nicolas Küchler; Anwar Hithnawi

3. "Flamingo: Multi-Round Single-Server Secure Aggregation with Applications to Private Federated Learning" [[Paper]](https://ieeexplore.ieee.org/document/10179434)
   - Yiping Ma; Jess Woods; Sebastian Angel; Antigoni Polychroniadou; Tal Rabin


## Decentralized Learning

1. "On the (In)security of Peer-to-Peer Decentralized Machine Learning" [[Paper]](https://www.computer.org/csdl/proceedings-article/sp/2023/933600a418/1NrbXMPH8QM)
   - Dario Pasquini; Mathilde Raynal; Carmela Troncoso

## Inference Privacy

1. "SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning" [[Paper]](https://ieeexplore.ieee.org/abstract/document/10179281)
   - Ahmed Salem; Giovanni Cherubin; David Evans; Boris Köpf; Andrew Paverd; Anshuman Suri; Shruti Tople; Santiago Zanella-Béguelin

2. "Analyzing Leakage of Personally Identifiable Information in Language Models" [[Paper]](https://ieeexplore.ieee.org/document/10179300) [[Code]](https://github.com/microsoft/analysing_pii_leakage)
   - Nils Lukas; Ahmed Salem; Robert Sim; Shruti Tople; Lukas Wutschitz; Santiago Zanella-Béguelin

### Membership Inference Attack

1. "Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference Perspective" [[Paper]](https://ieeexplore.ieee.org/document/10179463)
   - Shahbaz Rezaei; Zubair Shafiq; Xin Liu

### Property Inference Attack

1. "SNAP: Efficient Extraction of Private Properties with Poisoning" [[Paper]](https://ieeexplore.ieee.org/document/10179334)
   - Harsh Chaudhari; John Abascal; Alina Oprea; Matthew Jagielski; Florian Tramèr; Jonathan Ullman

## Intellectual Property

### Fingerprint

1. "PublicCheck: Public Integrity Verification for Services of Run-time Deep Models" [[Paper]](https://ieeexplore.ieee.org/abstract/document/10179380)
   - Shuo Wang; Sharif Abuadbba; Sidharth Agarwal; Kristen Moore; Ruoxi Sun; Minhui Xue; Surya Nepal; Seyit Camtepe; Salil Kanhere

### Model Extraction Attack

1. "D-DAE: Defense-Penetrating Model Extraction Attacks" [[Paper]](https://ieeexplore.ieee.org/document/10179406)
   - Yanjiao Chen; Rui Guan; Xueluan Gong; Jianshuo Dong; Meng Xue

## Others

1. "On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive Learning" [[Paper]](https://ieeexplore.ieee.org/document/10179315) [[Code]](https://github.com/YitingQu/meme-evolution)
   - Yiting Qu; Xinlei He; Shannon Pierson; Michael Backes; Yang Zhang; Savvas Zannettou
2. 

# [USENIX Security]
